\chapter{SegMatchAE}
\label{chap:segmatchAE}

This Chapter details the work following the implementation of SegMatch. In this part of the project, the goal was to design and implement a learning descriptor, that would improve the quality of descriptions and matches.\\

\section{Extending Segment Matching}
\label{sec:ae-intro}
%TODO

Recent work is showing neural networks as a versatile and promising machine learning technique. Despite initial promise in the years following the invention of the Perceptron \cite{perceptron} in 1958, neural networks did not show useful results, or superiority to other machine learning algorithms on many problems for some time. In the recent years (2006-) however, breakthrough results in the fields of audio (see WaveNet \cite{wavenet}), visual (see ? \cite{inception?}), natural language processing (see ? \cite{?}), game-agent (see AlphaGo \cite{alphago}), to cite a few, have led to increased research effort and adoption in consumer \cite{snapchat-face-recognition} and business \cite{google-cooling} technologies.\\

There is little doubt that neural networks can also be useful in the robotics field. With this in mind, and based on pre-existing research on classifying 3D segments using neural networks (see Subsection~\ref{subsec:voxnet}), it was decided that neural networks were an ideal test subject for improving SegMatch performance.\\

The description step was seen as showing the most potential for improvement. In addition, the description task shares similarities with 3D object classification, which is a current subject of machine learning research. Thus, the description step was selected as the section of the algorithm to be supplemented with a neural network model.\\

\section{Neural Networks for 3D Segment Recognition}
\label{sec:neural-nets}
%TODO

\subsection{Artificial Neural Networks - A Primer}
\label{subsec:primer}

In this subsection, the unacquainted reader can find a short summary of many concepts used in this project.

Another goal of this subsection is to define some terms used later in this chapter, such as terms relating to implementation details (\textit{hidden layer}, \textit{backpropagation}, etc \ldots).

\subsubsection{Simple Model}
\label{subsubsec:simple-model}

The simplest artificial neural network model is a series of layers, each containing a few artificial neurons. Inputs get propagated forwards through the network. Inspired by the way signals flow through a neuron's many synapses, each input to a neuron is multiplied by a particular weight. All of a neuron's weighted inputs are added together, a bias term is added, and the result is passed through the neuron's activation function $f(x)$, which can be for example the sigmoid function. The resulting value is the neuron's output.\\

All the neuron outputs of a layer become the inputs to all neurons in the next layer. This is called a \textit{fully-connected} layer architecture. The input values to the algorithm - are treated as though they were neuron outputs of an 'input' layer, and fed directly into the inputs of the first neuron layer.\\

The last neuron layer is called the 'output' layer, and its neurons activations form the output values of the algorithm. All layers between the 'input' and 'output' layer are referred to as 'hidden' layers.\\

In the simplest case, learning is achieved through \textit{backpropagation} of the output error. That is, the error between the model output and the target output (ideal output of the network, determined in advance for training purposes) is calculated. The gradient of this error w.r.t. the model parameters (weights and biases) is then computed, propagating backward from the output neurons all the way back to the first input layers. All parameters are then updated by a small amount according to the opposite direction of this gradient (this simple update rule is referred to as \textit{Gradient Descent}. When this process is repeated several times and for many examples, the output error is reduced.\\

\subsubsection{Deep Networks}

An arbitrary amount of hidden layers can theoretically be stacked behind each other. Networks consisting of many hidden layers are referred to as 'deep' neural networks, and are supposedly able to capture more complex relationships within their logical pathways than 'shallow' networks.\\

As is often repeated in the context of artificial neural networks, a shallow network consisting of a single neural network, if it has infinitely many neurons, can theoretically compute any function $f(inputs) = outputs$. In practice however, deeper networks are often used when attempting to comput complex functions.\\

However, deep neural networks used in such cases often have architectures and particularities which differ from the simple model presented in subsubsection \ref{subsubsec:simple-model}. This is due in part to instabilities which arise when backpropagating the error through many layers.\\ 

\subsubsection{Convolutional Neural Networks}

The intuition behind convolutional neural networks is to take advantage of repeating patterns in the model input. A neural network model which takes a whole image's pixel values as inputs, for example, is likely to be presented with underlying relationships in the input data which are repeated in several locations of the input.\\

Convolutional layers create small neural network layers, with a reduced amount of inputs $n\times n$ (for example, $n = 5$), commonly referred to as filters. A single filter is applied at each position in the full layer-input $N\times N$, taking the $n\times n$ surrounding values as filter inputs, and outputting a single value.\\

Filters can also be applied with \textit{strides}, meaning that the filter skips over every k input positions, leading to a reduced size layer-output.\\

Thus convolutional layers allow useful pattern learning in the input, with few parameters. On the other hand, convolutions generally require heavier computation. They have shown good results in many tasks, and are quite widespread especially with tasks where repeated patterns are expected in the input (computer vision, audio).\\

\subsubsection{Pooling}

\textit{Pooling} layers reduce the size of their output by applying a hardcoded filter at every position with a stride. For example, a 2x2 \textit{Max pooling} layer has a single max filter of size 2x2, which simply returns the max value of its inputs. This filter is applied with a stride of 2, resulting in an output half the size of the input.\\

\subsubsection{Other Architectures}

It should be mentioned that there are yet many other architectures of neural networks showing good results in current research, to name a few: Recurrent Neural Networks (RNN), Dynamic Neural Computers (DNC), Residual Networks (ResNets) and many more. These will not be discussed in this report.\\

\subsubsection{Optimizer}

Gradient Descent, mentioned in Subsubsection \ref{subsubsec:simple-model}, is a simple way, but not the most efficient, of finding local minima for the error function in the many-dimensional parameter space of the model.\\

Optimizers help navigate the many-dimensional parameter space more efficiently when performing the backpropagation step. They do so by implementing methods such as artificial momentum, looking ahead of the current position in this parameter space, and other techniques. This allows the backpropagation algorithm to reach local minima of the error function with fewer learning steps.\\

In this project, the neural networks were trained by using the ADAM optimizer. The Adaptive Moment Estimation (ADAM) optimizer computes learning rates for each parameter in the model, and adapts those rates based on previous fluctuations of gradients and previous parameter update values.\\

More information is available in the authors' paper \cite{adam}, where they also show empirical results of ADAM's learning speed-up. 

\subsection{Neural Networks for 3D Segment Classification}
\label{subsec:voxnet}

Maturana and Scherer \cite{voxnet} use 3D convolutions in their VoxNet model, in order to classify 3D segments. The motivation of VoxNet was to determine if progresses made through convnets in computer vision tasks could extend to 3D data.\\

VoxNet takes a 32x32x32 occupancy grid as input, and outputs a softmax classification of the segment.\\

Its first two layers are convolutions, wth respectively 32 5x5x5 filters and 32 3x3x3 filters, a 2x2 max pooling layer, a fully connected layer of size 128, and a softmax fully connected output layer of size $K$, $K$ being the number of possible classes to draw a prediction from.\\

Maturana and Scherer found that VoxNet performs at state-of-the-art accuracy.


\subsection{Unsupervised Learning with Neural Networks}
\label{subsec:autoencoder}
%TODO

In the SegMatch case, the present task does not require classification but description. As discussed in Section ~\ref{sec:description}, the description scenario entails no known targets such as in classification, but rather heuristics for relative positions of the segment descriptions. That is to say, the correct output of our model for a given segment is not known in advance. In addition, even if the true ideal description of each segment could be known in advance, there is as of yet no 3D segments dataset with those target descriptions available, which is necessary for supervised training. Creating such a dataset would be a time-consuming task and was not the goal of this project. On top of this, such a dataset might become obsolete as sensor-technology evolves, or when using a different segmentation algorithm.\\

For these reasons, unsupervised training was deemed a more promising method. In unsupervised training, no ground-truth is required to train the model, it can be trained with each new example extracted from the environment, with no processing before-hand.\\

An example of an unsupervised neural network architecture is the Autoencoder, in which an encoder network compresses the input to a small-dimensional representation, and a similar-sized decoder network attempts to decompress the representation back into the original input. The intuition is that, should the network be able to do this for many examples it has not seen before, it will have successfully learnt a meaningful representation of the inputs in n-dimensional space. As the output target is identical to the input, no ground-truth information is required for the training examples, which means that no hand-labeling or label databases are necessary.\\

Other types of unsupervised models exist, such as Adversarial Networks. They do not fall within the scope of this thesis report.

\subsection{Variational Bayes Autoencoder}
\label{subsec:variational-bayes}
%TODO

Kingma and Welling \cite{variational-autoencoder} present a modified autoencoder architecture, which shows superior prediction performance and learning efficiency than the standard autoencoder. The variational Bayes autoencoder does not only predict an n-value representation at the encoder output, but parameters to a probabilistic distribution of each of those values. In simplified terms, it can be designed to predict means and variances in the case of a standard distribution. A value is then sampled from each distribution, and the resulting n-values are passed to the decoder network.\\

The second trick in the paper \cite{variational-autoencoder} is to introduce a cost function for the autoencoder output which not only penalizes errors in the reconstruction (through for example cross-entropy loss between output prediction and true probability), but also the Kullbackâ€“Leibler divergence of the latent space prediction w.r.t. the true prior distribution in latent space.\\

\section{Implementation}
\label{sec:ae-implementation}

During the course of this project, we implemented a model in Tensorflow \cite{tensorflow}, and included it in the SegMatch algorithm.\\

The model comes in two architectures, with and without 3-dimensional convolutions.\\

In the meantime, a preprint paper by Brock et al.  \cite{voxel-autoencoder} briefly presents successful results on datasets using Variational Autoencoders for reconstructing Voxelized 3D data.
%TODO
GPU Speedup

\section{Results}
\label{sec:ae-results}

ModelNet database \cite{modelnet}

