\chapter{Introduction}
\label{sec:introduction}

This report is structured as follows: Chapter \ref{chap:segmatch} describes the implementations details of the segment-based loop closure algorithm which was developped during this project, and its usefulness and performance. The presented loop closure algorithm is from this point on referred to as SegMatch. SegMatch is also described and evaluated in Dub√© \cite{segmatch}.\\

Chapter \ref{chap:ae} explores the development of a learning-based enhancement to SegMatch, allowing a module of the algorithm to learn useful segment descriptions in an unsupervised fashion. The enhancement is implemented and tested, and the results are discussed. The enhanced SegMatch algorithm, with autoencoder-based description is from here on out referred to as SegMatchAE.\\

\section{Motivation for Range-Based SLAM Loop Closures}
\label{sec:motivation}

When mapping the environment, in the absence of global positioning information, or other mechanisms to prevent errors from accumulating, drift will inevitably occur. Loop closures are such a mechanism of error correction, where recognition of previously visited environment allows knowledge of one's relative position to be updated.\\ 

This project examined specifically the implementation of such a method in the case where mapping is performed on data collected by a range-based sensor.\\

Range-based sensors allow for consistent depth-measurement, and can do so in environments where vision-based sensors become untrustworthy due to illumination or weather. Often, vision based sensors requires relatively complex algorithms to estimate depth. Range sensors can thus be necessary in scenarios where robust depth information is important.\\

When mapping the environment with a range-based sensor, the same algorithms as for vision-based mapping can not be used with similar success. A cause is the difference in the data produced by both sensors. As a result, even though algorithms for vision-based loop closures have been demonstrated, to our knowledge, no mature range-based equivalent exists.\\

\section{State-of-the-Art}
\label{sec:SOTA}

The works presented in \cite{bosse2013place, zhuang20133, steder2010robust, steder2011place, Gawel2016} propose to extract local features from keypoints and perform matches on the basis of these features.

\citet{bosse2013place} extract keypoints directly from the point clouds and describe them with a 3D \textit{Gestalt} descriptor. Keypoints then vote for their nearest neighbours in a \textit{vote matrix} which is finally thresholded for recognizing places. Similar approach has been used in \cite{Gawel2016}.


Descriptors:\\ 

Fast Point Feature Histograms ~\cite{rusu2009fast}  \\

NBLD ~\cite{cieslewski2016point}\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
Zhuang \citet{zhuang20133} transform the local scans into bearing-angle images and extract Speeded Up Robust Features (SURFs) from these images. A strategy based on 3D spatial information is employed to order the scenes before matching the descriptors. \\

A similar technique by \citet{steder2010robust} first transforms the local scans into a range image.  Local features are extracted and compared to the ones stored in a database, employing the Euclidean distance for matching keypoints.

This work is extended in \cite{steder2011place} by using Normal-Aligned Radial Features (NARF) descriptors and a bag of words approach for matching.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

Zhang \citet{zhang2014loam} shows real-time mapping on range data. Odometry and mapping are performed in two phases: a high frequency pass extracts keypoints and matches them to estimate odometry between two scans, while a lower frequency pass assembles the scans into a map by using statistical analysis and nonlinear optimization. Offline loop-closure detection is mentioned.

\citet{bosse2013place} use a keypoint voting-based approach for finding places. The space is first segmented into two semi-overlapping voxel grids of 0.4m resolution. Keypoints are randomly selected and \textit{Gestallt} features computed. Nearest neighbour search is computed and votes are aggregated in the \textit{vote matrix} which is tresholded for recognizing places. A RANSAC based approach is used for transforming the corresponding keypoints into 6DoF transformations. Statistical modeling is applied for determining the vote threshold and the size of the neighbourhood.

\citet{steder2011place} first extracts \textit{normal-aligned radial featurest} (NARFs) which are parameterized by feature size, maximum number per image and support size. A dictionary is learned over the scans database and clustered in 200 words. For new images, NARF features are associated to their closest within dictionary and histograms of words are compared to reorder the database scans in the most likely to match order. Transformations computation and similarity evaluation is then performed going through the scans pile with a threshold on the maximum matching time.

Using global descriptors of the local point cloud for loop-closures is also proposed \cite{rohling2015fast,granstrom2011learning,magnusson2009automatic}.

\citet{rohling2015fast} propose to describe each local point cloud with a 1D histogram of point heights, assuming that the sensor keeps a constant height above the ground.  The height of every point above the ground is used for computing this description and it is assumed that the sensor keeps a constant height above the ground.  The histograms are then compared using the \textit{Wasserstein} metric for recognizing places.

\citet{granstrom2011learning} describe point clouds with rotation invariant features such as volume, nominal range, and range histogram.  Distances are computed for scalar features and cross-correlation for histogram features, and an AdaBoost classifier is trained to match places.  Finally, ICP is used for computing the relative pose between point clouds.

In another approach, \citet{magnusson2009automatic} split the cloud into overlapping grids and compute shape properties (spherical, linear, and several type of planar) of each cell and combine them into a matrix of surface shape histograms.  Matrices are weighted so that places with many points are not favoured.  Similar to other works, these descriptors are compared for finding loop-closures.


Other works have also proposed to use 3D segments or objects for the place recognition task.

\citet{fernandez2013fast}, for example, propose to perform place recognition by detecting planes in 3D environments.  Planes are identified through region growing and described by their centroid, area, elongation, and normal and principal vectors.  These are then accumulated in a graph where sub-graphs are composed of the planes 1-connected with a reference plane.  An interpretation tree is employed to search for the best match between two sub-graphs, and consistency tests are made for finding a rigid transformation between two matching sub-graphs.  The planes are accumulated in a graph and an interpretation tree is used to match sub-graphs.  A final geometric consistency test is conducted over the planes in the matched sub-graphs.

The work is extended in \cite{fernandez2016scene} to use the covariance of the plane parameters instead of the number of points in planes for matching.  This strategy is only applied to small, indoor environments and assumes a plane model for segments which is no longer valid in unstructured environment.

\citet{finman2015icraws} Present loop-closure detection by object-matching in indoor environments using RGB-D cameras.



SLAM with segments

A strategy for aligning Velodyne scans based on segments is proposed in \cite{douillard2012scan} where the Symmetric Shape Distance is used to compare and match segments as defined in \cite{douillard2014pipeline}.

Analogously, \cite{nieto2006scan} proposed an Extended Kalman Filter solution which uses segments as landmarks, rather than point features.
%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Motivations for SegMatch}
% 
% Segments save space
% 
% The use of segments for place recognition has several useful properties.
% 
% \section{Motivations for SegMatchAE}
% 
% Generalization
% Unsupervised
% Less heuristic-based

